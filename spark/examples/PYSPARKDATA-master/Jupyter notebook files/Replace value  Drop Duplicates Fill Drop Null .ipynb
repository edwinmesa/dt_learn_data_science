{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").config(conf=SparkConf()).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+\n",
      "|age|gender| name|\n",
      "+---+------+-----+\n",
      "|  5|     M| king|\n",
      "|  5|     M| king|\n",
      "| 10|     F|queen|\n",
      "|100|     F|queen|\n",
      "+---+------+-----+\n",
      "\n",
      "+-----+---+------+\n",
      "| name|age|gender|\n",
      "+-----+---+------+\n",
      "| king|  5|     M|\n",
      "|queen| 10|     F|\n",
      "|queen|100|     F|\n",
      "+-----+---+------+\n",
      "\n",
      "+-----+---+------+\n",
      "| name|age|gender|\n",
      "+-----+---+------+\n",
      "| king|  5|     M|\n",
      "|queen| 10|     F|\n",
      "+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping Duplicates\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([ \\\n",
    "                    Row(name='king', age=5,gender='M'), \\\n",
    "                    Row(name='king', age=5,gender='M'), \\\n",
    "                    Row(name='queen', age=10,gender='F'),\\\n",
    "                    Row(name='queen', age=100,gender='F')])\n",
    "\n",
    "'''\n",
    "For spark 1.6 use this code to create the above dataframe\n",
    "\n",
    "df = sc.parallelize([ \\\n",
    "                    Row(name='king', age=5,gender='M'), \\\n",
    "                    Row(name='king', age=5,gender='M'), \\\n",
    "                    Row(name='queen', age=10,gender='F'),\\\n",
    "                    Row(name='queen', age=100,gender='F')]).toDF()\n",
    "                    \n",
    "'''\n",
    "\n",
    "df.show()\n",
    "df.dropDuplicates().select(\"name\",\"age\",\"gender\").show()\n",
    "df.dropDuplicates([\"name\",\"gender\"]).select(\"name\",\"age\",\"gender\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|    a|  b|  c|\n",
      "+-----+---+---+\n",
      "| KING|  5|  m|\n",
      "| KING|  5|  m|\n",
      "|QUEEN| 15|  F|\n",
      "|QUEEN| 25|  F|\n",
      "|  RAJ| 30|  m|\n",
      "+-----+---+---+\n",
      "\n",
      "+-----+---+---+\n",
      "|    a|  b|  c|\n",
      "+-----+---+---+\n",
      "| king|  5|  m|\n",
      "| king|  5|  m|\n",
      "|queen| 15|  F|\n",
      "|queen| 25|  F|\n",
      "|  raj| 30|  m|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replacing the values in different columns \n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "df = spark.createDataFrame([ \\\n",
    "                    Row(a='king',b=5,c='m'), \\\n",
    "                    Row(a='king', b=5,c='m'), \\\n",
    "                    Row(a='queen', b=15,c='F'),\\\n",
    "                    Row(a='queen',b=25,c='F'),\\\n",
    "                    Row(a='raj',b=30,c='m')])\n",
    "\n",
    "df.show()\n",
    "df.replace([\"king\",\"queen\",\"raj\"],[\"KING\",\"QUEEN\",\"RAJ\"],\"a\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|gender| age| name|\n",
      "+------+----+-----+\n",
      "|     M|  10| KING|\n",
      "|     M|  10| KING|\n",
      "|  null|  10|QUEEN|\n",
      "|  null|null|QUEEN|\n",
      "|     M|null| null|\n",
      "+------+----+-----+\n",
      "\n",
      "+-------+---+-----+\n",
      "| gender|age| name|\n",
      "+-------+---+-----+\n",
      "|      M| 10| KING|\n",
      "|      M| 10| KING|\n",
      "|unknown| 10|QUEEN|\n",
      "|unknown|  0|QUEEN|\n",
      "|      M|  0| null|\n",
      "+-------+---+-----+\n",
      "\n",
      "+------+----+-----+\n",
      "|gender| age| name|\n",
      "+------+----+-----+\n",
      "|     M|  10| KING|\n",
      "|     M|  10| KING|\n",
      "|unkown|  10|QUEEN|\n",
      "|unkown|null|QUEEN|\n",
      "|     M|null| null|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling  null values\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "df = spark.createDataFrame([ \\\n",
    "                    Row(a='king',b=5,c='m'), \\\n",
    "                    Row(a='king', b=5,c='m'), \\\n",
    "                    Row(a='queen', b=15,c='F'),\\\n",
    "                    Row(a='queen',b=25,c='F'),\\\n",
    "                    Row(a='raj',b=30,c='m')])\n",
    "\n",
    "'''\n",
    "To get this data frame in spark 1.6\n",
    "\n",
    "df = sc.parallelize([ \\\n",
    "                    Row(a='king',b=5,c='m'), \\\n",
    "                    Row(a='king', b=5,c='m'), \\\n",
    "                    Row(a='queen', b=15,c='F'),\\\n",
    "                    Row(a='queen',b=25,c='F'),\\\n",
    "                    Row(a='raj',b=30,c='m')])\n",
    "\n",
    "'''\n",
    "df=df.select(f.when(df.c== \"m\",\"M\").alias(\"gender\"),f.when(df.b<20,10).alias(\"age\"),\\\n",
    "             f.when(df.a== \"king\",\"KING\").when(df.a==\"queen\",\"QUEEN\").alias(\"name\"))\n",
    "\n",
    "df.show()\n",
    "df.na.fill({'gender':'unknown','age':'0'}).show()\n",
    "df.na.fill(\"unkown\",subset=[\"gender\",\"age\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+\n",
      "|gender| age| name|\n",
      "+------+----+-----+\n",
      "|     M|  10| KING|\n",
      "|     M|  10| KING|\n",
      "|  null|  10|QUEEN|\n",
      "|  null|null|QUEEN|\n",
      "|  null|null| null|\n",
      "+------+----+-----+\n",
      "\n",
      "+------+---+----+\n",
      "|gender|age|name|\n",
      "+------+---+----+\n",
      "|     M| 10|KING|\n",
      "|     M| 10|KING|\n",
      "+------+---+----+\n",
      "\n",
      "+------+----+-----+\n",
      "|gender| age| name|\n",
      "+------+----+-----+\n",
      "|     M|  10| KING|\n",
      "|     M|  10| KING|\n",
      "|  null|  10|QUEEN|\n",
      "|  null|null|QUEEN|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping null values\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "df = spark.createDataFrame([ \\\n",
    "                    Row(a='king',b=5,c='m'), \\\n",
    "                    Row(a='king', b=5,c='m'), \\\n",
    "                    Row(a='queen', b=15,c='F'),\\\n",
    "                    Row(a='queen',b=25,c='F'),\\\n",
    "                    Row(a='raj',b=30,c='g')])\n",
    "df=df.select(f.when(df.c== \"m\",\"M\").alias(\"gender\"),f.when(df.b<20,10).alias(\"age\"),\\\n",
    "             f.when(df.a== \"king\",\"KING\").when(df.a==\"queen\",\"QUEEN\").alias(\"name\"))\n",
    "df.show()\n",
    "df.dropna('any').show()\n",
    "df.dropna('all').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
