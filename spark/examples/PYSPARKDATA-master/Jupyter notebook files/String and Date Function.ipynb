{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------+---------------+\n",
      "|order_customer_id|order_date|order_id|   order_status|\n",
      "+-----------------+----------+--------+---------------+\n",
      "|                1|2013-07-25|   11599|         CLOSED|\n",
      "|                2|2013-07-25|     256|PENDING_PAYMENT|\n",
      "+-----------------+----------+--------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").config(conf=SparkConf()).getOrCreate()\n",
    "\n",
    "# loading the data and assigning the schema.\n",
    "\n",
    "path_text_orders=\"file:///D://data-master/retail_db/orders\"\n",
    "\n",
    "orders_text=spark.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    " \"cast(split(value,',') [1] as date) order_date\",\n",
    " \"cast(split(value,',') [2] as int) order_id\",\n",
    " \"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "orders_table.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to stop the warnings and info and creating spark 1.6\n",
    "\n",
    "\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "'''launch pysaprk'''\n",
    "\n",
    "'''load the data'''\n",
    "\n",
    "path_text_orders=\"/user/pruthviraj/sqoop_text/orders\"\n",
    "\n",
    "orders_text=sqlContext.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "\"cast(split(value,',') [1] as date) order_date\",\n",
    "\"cast(split(value,',') [2] as int) order_id\",\n",
    "\"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "orders_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tilte](https://pysparktutorials.files.wordpress.com/2018/05/12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|   order_status|substr|\n",
      "+---------------+------+\n",
      "|         CLOSED|  CLOS|\n",
      "|PENDING_PAYMENT|  PEND|\n",
      "|       COMPLETE|  COMP|\n",
      "|         CLOSED|  CLOS|\n",
      "|       COMPLETE|  COMP|\n",
      "+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#substring on a cloumn\n",
    "\n",
    "\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    orders_table.order_status.substr(1,4).alias(\"substr\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Startswith "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|   order_status|starts_with|\n",
      "+---------------+-----------+\n",
      "|         CLOSED|       true|\n",
      "|PENDING_PAYMENT|      false|\n",
      "|       COMPLETE|      false|\n",
      "|         CLOSED|       true|\n",
      "|       COMPLETE|      false|\n",
      "+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the startswith will only provide the binary value\n",
    "\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    orders_table.order_status.startswith(\"CL\").alias(\"starts_with\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIKE operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|   order_status|like_mehtod|\n",
      "+---------------+-----------+\n",
      "|         CLOSED|       true|\n",
      "|PENDING_PAYMENT|      false|\n",
      "|       COMPLETE|      false|\n",
      "|         CLOSED|       true|\n",
      "|       COMPLETE|      false|\n",
      "+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#like operation \n",
    "\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    orders_table.order_status.like(\"CL%\").alias(\"like_mehtod\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rlike operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|   order_status|rlike_mehtod|\n",
      "+---------------+------------+\n",
      "|         CLOSED|       false|\n",
      "|PENDING_PAYMENT|        true|\n",
      "|       COMPLETE|       false|\n",
      "|         CLOSED|       false|\n",
      "|       COMPLETE|       false|\n",
      "+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rlike operation \n",
    "\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    orders_table.order_status.rlike(\"_\").alias(\"rlike_mehtod\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIN opertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|   order_status|isin_method|\n",
      "+---------------+-----------+\n",
      "|         CLOSED|       true|\n",
      "|PENDING_PAYMENT|      false|\n",
      "|       COMPLETE|       true|\n",
      "|         CLOSED|       true|\n",
      "|       COMPLETE|       true|\n",
      "+---------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isin operation\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    orders_table.order_status.isin(\"CLOSED\",\"COMPLETE\").alias(\"isin_method\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|order_customer_id|format_num|\n",
      "+-----------------+----------+\n",
      "|                1|    1.0000|\n",
      "|                2|    2.0000|\n",
      "|                3|    3.0000|\n",
      "|                4|    4.0000|\n",
      "|                5|    5.0000|\n",
      "+-----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#formatting the number\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "orders_table.select(orders_table.order_customer_id,\\\n",
    "                    f.format_number(orders_table.order_customer_id,4).alias(\"format_num\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+-----------------+\n",
      "|order_customer_id|   order_status|    format_string|\n",
      "+-----------------+---------------+-----------------+\n",
      "|                1|         CLOSED|         1,CLOSED|\n",
      "|                2|PENDING_PAYMENT|2,PENDING_PAYMENT|\n",
      "|                3|       COMPLETE|       3,COMPLETE|\n",
      "|                4|         CLOSED|         4,CLOSED|\n",
      "|                5|       COMPLETE|       5,COMPLETE|\n",
      "+-----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#formatting the string\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "orders_table.select(orders_table.order_customer_id,\\\n",
    "                    orders_table.order_status,\\\n",
    "                    f.format_string(\"%d,%s\",orders_table.order_customer_id,orders_table.order_status).\\\n",
    "                    alias(\"format_string\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date and time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_text_orders=\"file:///D://data-master/retail_db/orders\"\n",
    "\n",
    "orders_text=spark.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    " \"cast(split(value,',') [1] as string) order_date\",\n",
    " \"cast(split(value,',') [2] as int) order_id\",\n",
    " \"cast(split(value,',') [3] as string) order_status\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# format date, date subtraction, date addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          order_date|date_format|\n",
      "+--------------------+-----------+\n",
      "|2013-07-25 00:00:...|   00-25-13|\n",
      "|2013-07-25 00:00:...|   00-25-13|\n",
      "|2013-07-25 00:00:...|   00-25-13|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+----------+\n",
      "|          order_date|  date_sub|\n",
      "+--------------------+----------+\n",
      "|2013-07-25 00:00:...|2013-07-15|\n",
      "|2013-07-25 00:00:...|2013-07-15|\n",
      "|2013-07-25 00:00:...|2013-07-15|\n",
      "+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+----------+\n",
      "|          order_date|  date_add|\n",
      "+--------------------+----------+\n",
      "|2013-07-25 00:00:...|2013-08-04|\n",
      "|2013-07-25 00:00:...|2013-08-04|\n",
      "|2013-07-25 00:00:...|2013-08-04|\n",
      "+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#date format, date subtractin and date date addition\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.date_format(orders_table.order_date,\"mm-dd-yy\").alias(\"date_format\")).show(3)\n",
    "\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.date_sub(orders_table.order_date,10).alias(\"date_sub\")).show(3)\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.date_sub(orders_table.order_date,-10).alias(\"date_add\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datedifference, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|          order_date|hour|\n",
      "+--------------------+----+\n",
      "|2013-07-25 00:00:...|   0|\n",
      "|2013-07-25 00:00:...|   0|\n",
      "|2013-07-25 00:00:...|   0|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+----------+---------+\n",
      "|     date1|     date2|daitediff|\n",
      "+----------+----------+---------+\n",
      "|2013-07-25|2013-08-04|      -10|\n",
      "|2013-07-25|2013-08-04|      -10|\n",
      "|2013-07-25|2013-08-04|      -10|\n",
      "+----------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Find hour\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.hour(orders_table.order_date).alias(\"hour\")).show(3)\n",
    "\n",
    "orders_table.select(orders_table.order_date.cast(\"date\").alias(\"date1\"),\\\n",
    "                    f.date_sub(orders_table.order_date,-10).alias(\"date2\"),\\\n",
    "                    f.datediff(\"order_date\",f.date_sub(orders_table.order_date,-10)).alias(\"daitediff\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day of week, month ,year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          order_date|day_of_week|\n",
      "+--------------------+-----------+\n",
      "|2013-07-25 00:00:...|          5|\n",
      "|2013-07-25 00:00:...|          5|\n",
      "|2013-07-25 00:00:...|          5|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------------+\n",
      "|          order_date|day_of_month|\n",
      "+--------------------+------------+\n",
      "|2013-07-25 00:00:...|          25|\n",
      "|2013-07-25 00:00:...|          25|\n",
      "|2013-07-25 00:00:...|          25|\n",
      "+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|          order_date|day_of_year|\n",
      "+--------------------+-----------+\n",
      "|2013-07-25 00:00:...|        206|\n",
      "|2013-07-25 00:00:...|        206|\n",
      "|2013-07-25 00:00:...|        206|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#day of week,month,year\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.dayofweek(orders_table.order_date).alias(\"day_of_week\")).show(3)\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.dayofmonth(orders_table.order_date).alias(\"day_of_month\")).show(3)\n",
    "\n",
    "orders_table.select(orders_table.order_date,\\\n",
    "                    f.dayofyear(orders_table.order_date).alias(\"day_of_year\")).show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
