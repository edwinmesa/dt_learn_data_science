{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------+---------------+\n",
      "|order_customer_id|order_date|order_id|   order_status|\n",
      "+-----------------+----------+--------+---------------+\n",
      "|                1|2013-07-25|   11599|         CLOSED|\n",
      "|                2|2013-07-25|     256|PENDING_PAYMENT|\n",
      "+-----------------+----------+--------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use tis command if you are using the jupyter notebook\n",
    "\n",
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").config(conf=SparkConf()).getOrCreate()\n",
    "\n",
    "# loading the data and assigning the schema.\n",
    "\n",
    "path_text_orders=\"file:///D://data-master/retail_db/orders\"\n",
    "\n",
    "orders_text=spark.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "                                     \"cast(split(value,',') [1] as date) order_date\",\n",
    "                                     \"cast(split(value,',') [2] as int) order_id\",\n",
    "                                      \"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "orders_table.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launching in CLOUDERA vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to stop the warnings and info in saprk 1.6\n",
    "\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "'''launch pysaprk'''\n",
    "\n",
    "'''load the data'''\n",
    "\n",
    "path_text_orders=\"/user/pruthviraj/sqoop_text/orders\"\n",
    "\n",
    "orders_text=sqlContext.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "                                     \"cast(split(value,',') [1] as date) order_date\",\n",
    "                                     \"cast(split(value,',') [2] as int) order_id\",\n",
    "                                      \"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "orders_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tilte](https://pysparktutorials.files.wordpress.com/2018/05/12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|order_customer_id|range_filter|\n",
      "+-----------------+------------+\n",
      "|              200|        true|\n",
      "|              201|        true|\n",
      "|              202|        true|\n",
      "|              203|        true|\n",
      "|              204|        true|\n",
      "|              205|        true|\n",
      "|              206|        true|\n",
      "|              207|        true|\n",
      "|              208|        true|\n",
      "|              209|        true|\n",
      "|              210|        true|\n",
      "+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#range condition\n",
    "\n",
    "orders_table.select(orders_table.order_customer_id,\\\n",
    "orders_table.order_customer_id.between(200,210).alias(\"range_filter\")).\\\n",
    "filter(\"range_filter='true'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|   order_status|  when_condition|\n",
      "+---------------+----------------+\n",
      "|         CLOSED|          closed|\n",
      "|PENDING_PAYMENT| pending_payment|\n",
      "|       COMPLETE|        complete|\n",
      "|         CLOSED|          closed|\n",
      "|       COMPLETE|        complete|\n",
      "|       COMPLETE|        complete|\n",
      "|       COMPLETE|        complete|\n",
      "|     PROCESSING|yet to determine|\n",
      "|PENDING_PAYMENT| pending_payment|\n",
      "|PENDING_PAYMENT| pending_payment|\n",
      "+---------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case condition using the when method\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "orders_table.select(orders_table.order_status,\\\n",
    "                    f.when(orders_table.order_status==\"COMPLETE\",\"complete\").\\\n",
    "                    when(orders_table.order_status==\"CLOSED\",\"closed\").\\\n",
    "                    when(orders_table.order_status==\"PENDING_PAYMENT\",\"pending_payment\").\\\n",
    "otherwise(\"yet to determine\").alias(\"when_condition\")).show(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
