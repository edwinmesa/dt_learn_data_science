{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").config(conf=SparkConf()).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering dataframe as sql table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------+---------------+\n",
      "|order_customer_id|order_date|order_id|   order_status|\n",
      "+-----------------+----------+--------+---------------+\n",
      "|                1|2013-07-25|   11599|         CLOSED|\n",
      "|                2|2013-07-25|     256|PENDING_PAYMENT|\n",
      "|                3|2013-07-25|   12111|       COMPLETE|\n",
      "|                4|2013-07-25|    8827|         CLOSED|\n",
      "|                5|2013-07-25|   11318|       COMPLETE|\n",
      "|                6|2013-07-25|    7130|       COMPLETE|\n",
      "|                7|2013-07-25|    4530|       COMPLETE|\n",
      "|                8|2013-07-25|    2911|     PROCESSING|\n",
      "|                9|2013-07-25|    5657|PENDING_PAYMENT|\n",
      "|               10|2013-07-25|    5648|PENDING_PAYMENT|\n",
      "|               11|2013-07-25|     918| PAYMENT_REVIEW|\n",
      "|               12|2013-07-25|    1837|         CLOSED|\n",
      "|               13|2013-07-25|    9149|PENDING_PAYMENT|\n",
      "|               14|2013-07-25|    9842|     PROCESSING|\n",
      "|               15|2013-07-25|    2568|       COMPLETE|\n",
      "|               16|2013-07-25|    7276|PENDING_PAYMENT|\n",
      "|               17|2013-07-25|    2667|       COMPLETE|\n",
      "|               18|2013-07-25|    1205|         CLOSED|\n",
      "|               19|2013-07-25|    9488|PENDING_PAYMENT|\n",
      "|               20|2013-07-25|    9198|     PROCESSING|\n",
      "+-----------------+----------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registering dataframe as sql table\n",
    "\n",
    "# loading the data and assigning the schema.\n",
    "\n",
    "path_text_orders=\"file:///D://data-master/retail_db/orders\"\n",
    "\n",
    "orders_text=spark.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "                                     \"cast(split(value,',') [1] as date) order_date\",\n",
    "                                     \"cast(split(value,',') [2] as int) order_id\",\n",
    "                                      \"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "\n",
    "'''if you are using saprk 1.6 use the below command\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(dataframe, \"table_name\")\n",
    "sqlContext.sqlContext.sql(\"select * from table_name\")\n",
    "\n",
    "'''\n",
    "\n",
    "orders_table.createOrReplaceTempView(\"orders_table\")\n",
    "\n",
    "\n",
    "spark.sql(\"select * from orders_table\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using sql transformer machine learning feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------+---------------+\n",
      "|order_customer_id|order_date|order_id|   order_status|\n",
      "+-----------------+----------+--------+---------------+\n",
      "|                1|2013-07-25|   11599|         CLOSED|\n",
      "|                3|2013-07-25|   12111|       COMPLETE|\n",
      "|                5|2013-07-25|   11318|       COMPLETE|\n",
      "|               24|2013-07-25|   11441|         CLOSED|\n",
      "|               38|2013-07-25|   11586|     PROCESSING|\n",
      "|               40|2013-07-25|   12092|PENDING_PAYMENT|\n",
      "|               48|2013-07-25|   12186|     PROCESSING|\n",
      "|               51|2013-07-25|   12271|         CLOSED|\n",
      "|               59|2013-07-25|   11644|PENDING_PAYMENT|\n",
      "|               70|2013-07-25|   11809|PENDING_PAYMENT|\n",
      "|               94|2013-07-25|   11589|     PROCESSING|\n",
      "|               99|2013-07-25|   11542|PENDING_PAYMENT|\n",
      "|              100|2013-07-25|   12131|     PROCESSING|\n",
      "|              103|2013-07-25|   12256|     PROCESSING|\n",
      "|              108|2013-07-26|   12149|     PROCESSING|\n",
      "|              134|2013-07-26|   12081|PENDING_PAYMENT|\n",
      "|              141|2013-07-26|   12128|       COMPLETE|\n",
      "|              149|2013-07-26|   11431|       COMPLETE|\n",
      "|              158|2013-07-26|   12345|        PENDING|\n",
      "|              168|2013-07-26|   11794|PENDING_PAYMENT|\n",
      "+-----------------+----------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL TRANSFORMER STATEMENTS ONLY in 2.1 and above\n",
    "\n",
    "path_text_orders=\"file:///D://data-master/retail_db/orders\"\n",
    "\n",
    "orders_text=spark.read.format(\"text\").load(path_text_orders)\n",
    "\n",
    "orders_table=orders_text.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "                                            \"cast(split(value,',') [1] as date) order_date\",\n",
    "                                            \"cast(split(value,',') [2] as int) order_id\",\n",
    "                                            \"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "'''movies is a dataframe. this shows how a (SQL) select statement can be applied on\n",
    "the dataframe without creating the dataframe'''\n",
    "\n",
    "sqlTrans = SQLTransformer(statement=\"SELECT * FROM __THIS__ where order_id >11000\")\n",
    "\n",
    "sqlTrans.transform(orders_table).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
