{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just copy past the code in pyspark,make sure to include the correct path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 1.a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''calculate total number COMPLETE, CLOSED and PROCESSING transactions for  each state \n",
    "where the each of the transaction status count is greater then 50 and \n",
    "sort the final output descending order of the state and ascending order of the count.\n",
    "The output should be \" , \" separated text file with gzip compression written \n",
    "to \"/user/cloudera/answer/question1/text\" and must contain single file in the destination'''\n",
    "\n",
    "orders=\"/user/pruthviraj/sqoop_text/orders\"\n",
    "orders=sqlContext.read.format(\"text\").load(orders)\n",
    "orders=orders.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "\"cast(split(value,',') [1] as date) order_date\",\n",
    "\"cast(split(value,',') [2] as int) order_id\",\n",
    "\"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "customer=\"file:///D://data-master/retail_db/customers\"\n",
    "customer=spark.read.format(\"text\").load(customer)\n",
    "customer=customer.selectExpr(\"cast(split(value,',') [0] as int) customer_id\",\n",
    "\"cast(split(value,',') [1] as string) customer_fname\",\n",
    "\"cast(split(value,',') [2] as string) customer_lname\",\n",
    "\"cast(split(value,',') [3] as string) customer_email\",\n",
    "\"cast(split(value,',') [4] as string) customer_password\",\n",
    "\"cast(split(value,',') [5] as string) customer_street\",\n",
    "\"cast(split(value,',') [6] as string) customer_city\",\n",
    "\"cast(split(value,',') [7] as string) customer_state\",\n",
    "\"cast(split(value,',') [8] as string) customer_zipcode\")\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "customer.join(orders,customer.customer_id==orders.order_customer_id,\"inner\").\\\n",
    "groupBy(customer.customer_state,orders.order_status).\\\n",
    "agg(f.count(orders.order_customer_id).alias(\"count\")).\\\n",
    "filter(\"order_status in ('COMPLETE','CLOSED','PROCESSING')\").where(\"count >50\").\\\n",
    "orderBy([\"customer_state\",\"count\"],ascending=[0,1]).\\\n",
    "repartition(1,customer.customer_state).\\\n",
    "select(f.format_string(\"%s,%s,%d\",\"customer_state\",\"order_status\",\"count\").alias('ANSWER')).\\\n",
    "rdd.saveAsTextFile(\"/user/cloudera/answer/question1/text\",\"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# answer 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''calculate total number COMPLETE, CLOSED and PROCESSING transactions for  each state \n",
    "where the each of the transaction status count is greater then 50 and \n",
    "sort the final output descending order of the state and ascending order of the count.\n",
    "The output should be JSON file with gzip compression written \n",
    "to \"/user/cloudera/answer/question1/json\" and must contain three file in the destination'''\n",
    "\n",
    "orders=\"/user/pruthviraj/sqoop_text/orders\"\n",
    "orders=sqlContext.read.format(\"text\").load(orders)\n",
    "orders=orders.selectExpr(\"cast(split(value,',') [0] as int) order_customer_id\",\n",
    "\"cast(split(value,',') [1] as date) order_date\",\n",
    "\"cast(split(value,',') [2] as int) order_id\",\n",
    "\"cast(split(value,',') [3] as string) order_status\")\n",
    "\n",
    "customer=\"file:///D://data-master/retail_db/customers\"\n",
    "customer=spark.read.format(\"text\").load(customer)\n",
    "customer=customer.selectExpr(\"cast(split(value,',') [0] as int) customer_id\",\n",
    "\"cast(split(value,',') [1] as string) customer_fname\",\n",
    "\"cast(split(value,',') [2] as string) customer_lname\",\n",
    "\"cast(split(value,',') [3] as string) customer_email\",\n",
    "\"cast(split(value,',') [4] as string) customer_password\",\n",
    "\"cast(split(value,',') [5] as string) customer_street\",\n",
    "\"cast(split(value,',') [6] as string) customer_city\",\n",
    "\"cast(split(value,',') [7] as string) customer_state\",\n",
    "\"cast(split(value,',') [8] as string) customer_zipcode\")\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "customer.join(orders,customer.customer_id==orders.order_customer_id,\"inner\").\\\n",
    "groupBy(customer.customer_state,orders.order_status).\\\n",
    "agg(f.count(orders.order_customer_id).alias(\"count\")).\\\n",
    "filter(\"order_status in ('COMPLETE','CLOSED','PROCESSING')\").where(\"count >50\").\\\n",
    "orderBy([\"customer_state\",\"count\"],ascending=[0,1]).\\\n",
    "repartition(3,customer.customer_state).toJSON().\\\n",
    "toJSON().saveAsTextFile(\"/user/cloudera/answer/question1/json\",\"org.apache.hadoop.io.compress.GzipCodec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample output for both the question is same except the writting format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+-----------------+\n",
    "|           ANSWER|\n",
    "+-----------------+\n",
    "|     TX,CLOSED,78|\n",
    "| TX,PROCESSING,78|\n",
    "|  TX,COMPLETE,212|\n",
    "|    PR,CLOSED,556|\n",
    "|PR,PROCESSING,559|\n",
    "| PR,COMPLETE,1566|\n",
    "|   PA,COMPLETE,91|\n",
    "|   OH,COMPLETE,92|\n",
    "|     NY,CLOSED,88|\n",
    "| NY,PROCESSING,97|\n",
    "|  NY,COMPLETE,259|\n",
    "|   NJ,COMPLETE,69|\n",
    "|   NC,COMPLETE,52|\n",
    "|   MI,COMPLETE,72|\n",
    "|     IL,CLOSED,62|\n",
    "| IL,PROCESSING,68|\n",
    "|  IL,COMPLETE,168|\n",
    "|   GA,COMPLETE,54|\n",
    "|  FL,COMPLETE,134|\n",
    "|    CA,CLOSED,205|\n",
    "+-----------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envSpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b084bd5d932fbe9640f9116fd74048650a204a045aa4757b00e4e8784d9ce36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
